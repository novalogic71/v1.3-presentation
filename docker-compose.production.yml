version: '3.8'

# Production Docker Compose Configuration
# Features:
# - Redis for persistent job queues
# - Supervisord for process management
# - Automatic restarts with proper health checks
# - Log rotation and persistence

services:
  # Redis for job queue persistence
  redis:
    image: redis:7-alpine
    container_name: sync-analyzer-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy volatile-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - sync-analyzer-network
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Main application with supervisord
  sync-analyzer:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: sync-analyzer-app
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      # Mount data directory (read-only for safety)
      - /mnt/data:/mnt/data:ro
      # Persistent volumes for application data
      - ./uploads:/app/uploads
      - ./ai_models:/app/ai_models
      - ./logs:/app/logs
      - ./reports:/app/reports
      - ./sync_reports:/app/sync_reports
      - ./optimized_sync_reports:/app/optimized_sync_reports
      - ./repaired_sync_files:/app/repaired_sync_files
    environment:
      - PYTHONUNBUFFERED=1
      - MOUNT_PATH=/mnt/data
      - PORT_API=8000
      - DEBUG=false
      - 'ALLOWED_ORIGINS=["*"]'
      - LOG_LEVEL=INFO
      - LOG_FILE=/app/logs/app.log
      - UPLOAD_DIR=/app/uploads
      - AI_MODEL_CACHE_DIR=/app/ai_models
      # Redis connection
      - REDIS_URL=redis://redis:6379/0
      # GPU support
      - NVIDIA_VISIBLE_DEVICES=all
      - USE_GPU=true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 90s
    # GPU support (optional - remove if no GPU)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 8G
    networks:
      - sync-analyzer-network
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"

networks:
  sync-analyzer-network:
    driver: bridge

volumes:
  redis_data:
    driver: local

