# ðŸš€ Complete Sync Analysis System with Auto-Repair - Usage Guide

This comprehensive system provides advanced sync analysis with formatted reporting, CSV batch processing, intelligent auto-repair, and LLM-enhanced insights. The system now **always uses the long method** for thorough analysis and includes **smart playback preview** for corrections.

## ðŸ”§ **NEW: Auto-Repair Workflow (Recommended)**

The system now supports intelligent auto-repair with comprehensive packaging. **All analysis now uses the long method for maximum accuracy.**

```bash
# Auto-repair with default settings (100ms threshold)
python continuous_sync_monitor.py master.mov dub.mov --auto-repair

# Auto-repair with custom threshold and package creation
python continuous_sync_monitor.py master.mov dub.mov --auto-repair --repair-threshold 50 --create-package

# Complete workflow with custom output
python continuous_sync_monitor.py master.mov dub.mov \
  --auto-repair --repair-output repaired_dub.mov \
  --create-package --package-dir ./repair_results \
  --output analysis.json --plot sync_chart.png

# Using optimized CLI with auto-repair
python -m sync_analyzer.cli.optimized_sync_cli master.mov dub.mov \
  --auto-repair --create-package --gpu
```

## ðŸ“Š **Method 1: Analysis-Only (Basic)**

```bash
# Basic analysis (now uses long method automatically)
python continuous_sync_monitor.py master.mov dub.mov

# With JSON export
python continuous_sync_monitor.py master.mov dub.mov --output analysis.json

# With visualization
python continuous_sync_monitor.py master.mov dub.mov --output analysis.json --plot sync_chart.png

# High-resolution analysis
python continuous_sync_monitor.py master.mov dub.mov --chunk-size 20 --output detailed.json
```

## ðŸ”— **Method 2: Complete Command Chain (Single File + Formatted Report)**

### **Automated Chain:**
```bash
# Analysis + Formatted Report in one command
python continuous_sync_monitor.py master.mov dub.mov \
  --output analysis.json --plot chart.png && \
python sync_report_analyzer.py analysis.json \
  --name "Episode Name" --output formatted_report.md
```

### **LLM-Enhanced Reporting:**
```bash
# Analysis + LLM-Generated Professional Report
python continuous_sync_monitor.py master.mov dub.mov \
  --output analysis.json --plot chart.png && \
python llm_report_formatter.py analysis.json \
  --name "Episode Name" --output llm_report.md \
  --model llama3.2 --fallback
```

### **Complete Professional Workflow:**
```bash
#!/bin/bash
# Professional sync analysis with all outputs
MASTER="master.mov"
DUB="dub.mov" 
EPISODE="Episode 101"
OUTPUT_DIR="results"

mkdir -p "$OUTPUT_DIR"

# 1. Run comprehensive analysis
python continuous_sync_monitor.py "$MASTER" "$DUB" \
  --output "$OUTPUT_DIR/analysis.json" \
  --plot "$OUTPUT_DIR/sync_chart.png" \
  --chunk-size 30 --detailed

# 2. Generate formatted report
python sync_report_analyzer.py "$OUTPUT_DIR/analysis.json" \
  --name "$EPISODE" \
  --output "$OUTPUT_DIR/formatted_report.md"

# 3. Generate LLM professional report
python llm_report_formatter.py "$OUTPUT_DIR/analysis.json" \
  --name "$EPISODE" \
  --output "$OUTPUT_DIR/professional_report.md" \
  --fallback

echo "âœ… Complete analysis ready in $OUTPUT_DIR/"
```

## ðŸ“‹ **Method 3: CSV Batch Processing**

### **CSV Format Requirements:**

```csv
master_file,dub_file,episode_name,chunk_size,notes
/path/to/master1.mov,/path/to/dub1.mov,Episode 101,45,First episode
/path/to/master2.mov,/path/to/dub2.mov,Episode 102,30,Quick analysis
/path/to/master3.mov,/path/to/dub3.mov,Episode 103,60,Detailed analysis
```

**Required columns:**
- `master_file`: Path to master/reference video
- `dub_file`: Path to dub/test video
- `episode_name`: Display name for the episode

**Optional columns:**
- `chunk_size`: Analysis granularity (default: 45s)
- `notes`: Any additional information

### **Batch Processing Commands:**

```bash
# Basic batch processing
python csv_batch_processor.py example_batch.csv --output-dir batch_results/

# With visualization and custom workers
python csv_batch_processor.py batch_files.csv \
  --output-dir results/ \
  --plot \
  --max-workers 4

# High-throughput processing
python csv_batch_processor.py large_batch.csv \
  --output-dir production_results/ \
  --max-workers 8 \
  --plot
```

### **Batch Processing Outputs:**

Each batch run creates:
- `batch_processing_summary.json` - Complete processing statistics
- `batch_results_summary.csv` - Spreadsheet-friendly summary
- `{episode_name}_analysis.json` - Individual analysis data
- `{episode_name}_sync_chart.png` - Sync visualization (if `--plot` used)
- `{episode_name}_formatted_report.md` - Professional report for each episode

## ðŸ¤– **LLM-Enhanced Report Generation**

### **Setup LLM (Ollama):**
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull model
ollama pull llama3.2

# Start Ollama service
ollama serve
```

### **LLM Report Generation:**
```bash
# Generate intelligent report with LLM
python llm_report_formatter.py analysis.json \
  --name "Episode 101" \
  --output intelligent_report.md \
  --model llama3.2

# With custom endpoint
python llm_report_formatter.py analysis.json \
  --name "Episode 101" \
  --model-endpoint "http://localhost:11434/api/generate" \
  --fallback
```

### **Training LLM for Better Reports:**
```bash
# Create training examples directory
mkdir llm_training_examples/

# Add example JSON files and their ideal markdown reports
cp example_analysis.json llm_training_examples/
cp example_ideal_report.md llm_training_examples/example_analysis.md

# Train/improve the LLM formatter
python llm_report_formatter.py --train llm_training_examples/
```

## ðŸŒ **API and Web UI Integration**

### **NEW: Complete Workflow API:**

```bash
# Start complete analyze-and-repair workflow
curl -X POST "http://localhost:8000/api/v1/workflows/analyze-and-repair" \
  -H "Content-Type: application/json" \
  -d '{
    "master_file": "/mnt/data/master.mov",
    "dub_file": "/mnt/data/dub.mov",
    "episode_name": "Episode 101",
    "auto_repair": true,
    "repair_threshold": 100.0,
    "create_package": true
  }'

# Check workflow status
curl -X GET "http://localhost:8000/api/v1/workflows/analyze-and-repair/{workflow_id}/status"

# Download results
curl -X GET "http://localhost:8000/api/v1/workflows/analyze-and-repair/{workflow_id}/download/package"
curl -X GET "http://localhost:8000/api/v1/workflows/analyze-and-repair/{workflow_id}/download/repaired"
```

### **Other API Endpoints:**

```bash
# Get formatted report via API
curl -X GET "http://localhost:8000/api/v1/reports/{analysis_id}/formatted?episode_name=Episode%20101"

# Upload CSV for batch processing
curl -X POST "http://localhost:8000/api/v1/reports/batch/csv" \
  -F "file=@batch.csv" \
  -F "output_dir=api_results"

# Start batch processing
curl -X POST "http://localhost:8000/api/v1/reports/batch/{batch_id}/process?max_workers=4&generate_plots=true"

# Check batch status
curl -X GET "http://localhost:8000/api/v1/reports/batch/{batch_id}/status"
```

### **Enhanced Web UI Features:**
- **ðŸ”§ Smart Playback Preview**: Real-time correction preview with time-variable adjustments
- **ðŸŽµ Audio Comparison**: A/B comparison between original and corrected audio
- **ðŸ“Š Interactive Timeline**: Visual correction segments with quality indicators
- **âš¡ Long Method Processing**: All analysis now uses comprehensive chunked processing
- **ðŸ”„ Auto-Repair Integration**: Built-in repair workflow with package creation
- **CSV Upload**: Drag-and-drop CSV files for batch processing
- **Real-time Progress**: Monitor batch processing with live updates
- **Formatted Reports**: View professional reports in browser
- **Download Results**: Export summaries, reports, and visualizations
- **Multi-GPU Support**: Automatic workload distribution

## ðŸ”§ **Configuration and Optimization**

### **Performance Tuning:**

```bash
# High-speed analysis (trade accuracy for speed)
python continuous_sync_monitor.py master.mov dub.mov \
  --chunk-size 60 --output quick_analysis.json

# Maximum accuracy (slower)
python continuous_sync_monitor.py master.mov dub.mov \
  --chunk-size 15 --output detailed_analysis.json

# GPU optimization for batch processing
python csv_batch_processor.py batch.csv \
  --output-dir results/ \
  --max-workers 8  # Use all GPUs
```

### **Quality Control Integration:**
```bash
# Quick spot-check at specific times
python quick_sync_check.py master.mov dub.mov 0 60 120 300 600

# Continuous monitoring + QC
python continuous_sync_monitor.py master.mov dub.mov \
  --output analysis.json --detailed && \
python sync_report_analyzer.py analysis.json \
  --name "QC Report" --output qc_report.md
```

## ðŸ“ˆ **Output Formats and Examples**

### **JSON Analysis Output:**
```json
{
  "analysis_id": "analysis_20250912_...",
  "master_duration": 1383.0,
  "timeline": [
    {
      "start_time": 0.0,
      "offset_seconds": -2.463,
      "confidence": 0.031,
      "reliable": false,
      "quality": "poor"
    }
  ],
  "drift_analysis": {
    "has_drift": false,
    "drift_magnitude": 0.0,
    "drift_summary": "Consistent sync across file"
  }
}
```

### **Formatted Report Output:**
```markdown
# ðŸ“Š Episode 101 Sync Analysis Report

**File Duration:** 23.0 min
**Reliable Chunks:** 1/61 (1.6%)

## ðŸ” Sync Drift Analysis by Phases:

1. ðŸ”´ **Critical Drift Crisis** (0.0-23.2 min): Catastrophic sync failure
   - Multiple problematic regions detected
   - Requires immediate attention

## ðŸ’¡ Recommendations:
- ðŸ”§ **Time-variable sync correction needed**
- ðŸŽ¬ **Manual review recommended**
```

### **Batch Summary:**
```
ðŸ”¥ CSV Batch Sync Processor
ðŸ“Š File pairs to process: 25
âš¡ Max parallel workers: 4
ðŸ“ˆ Generate plots: Yes
ðŸ’¾ Total processing time: 15.2 minutes
ðŸŽ¯ Throughput: 1.6 episodes/minute
âœ… Success rate: 92% (23/25)
```

## ðŸš€ **Quick Start Examples**

### **Single File Analysis:**
```bash
python continuous_sync_monitor.py master.mov dub.mov \
  --output report.json --plot chart.png --chunk-size 30
```

### **Professional Report Generation:**
```bash
python sync_report_analyzer.py report.json \
  --name "My Episode" --output professional_report.md
```

### **CSV Batch Processing:**
```bash
python csv_batch_processor.py files.csv --output-dir results/ --plot
```

### **Complete Professional Workflow:**
```bash
# Use the provided example
python csv_batch_processor.py example_batch.csv \
  --output-dir complete_analysis/ \
  --plot --max-workers 2
```


The batch processing started successfully! It detected 2 file pairs and is using 2 workers across the 3
   available GPUs. Let me show you what you now have:

  ðŸŽ‰ Complete Implementation Summary

  You now have a comprehensive sync analysis system with all requested features:

  âœ… Method 2: Complete Command Chain

  # Single file analysis with formatted report
  python continuous_sync_monitor.py master.mov dub.mov \
    --output analysis.json --plot chart.png && \
  python sync_report_analyzer.py analysis.json --name "Episode"

  âœ… Method 3: CSV Batch Processing

  # Batch process from CSV file
  python csv_batch_processor.py example_batch.csv --output-dir results/ --plot

  âœ… Enhanced API Endpoints

  - GET /reports/{analysis_id}/formatted - Get formatted reports
  - POST /reports/batch/csv - Upload CSV for batch processing
  - POST /reports/batch/{batch_id}/process - Start batch processing
  - GET /reports/batch/{batch_id}/status - Monitor batch progress

  âœ… Web UI Enhancements

  - CSV Upload Interface: Drag-and-drop CSV files
  - Real-time Batch Monitoring: Live progress tracking
  - Formatted Report Viewer: Professional report display
  - Download Options: Export summaries and reports

  âœ… LLM Integration

  # AI-powered professional reports
  python llm_report_formatter.py analysis.json \
    --name "Episode" --model llama3.2 --fallback

  ðŸš€ Key Features You Can Use Right Now:

  1. Professional Formatted Reports: The type I showed you earlier
  2. CSV Batch Processing: Process dozens of file pairs automatically
  3. Multi-GPU Distribution: Automatic workload balancing
  4. Web Interface: Complete UI for CSV upload and monitoring
  5. API Integration: REST endpoints for all functionality
  6. LLM Enhancement: AI-powered intelligent report generation

  ðŸ“‹ Example Usage:

  For the formatted reports you wanted:
  python sync_report_analyzer.py rubble_crew_analysis.json --name "RubbleAndCrew Episode 101"

  For CSV batch processing:
  python csv_batch_processor.py example_batch.csv --output-dir results/ --plot --max-workers 3

  For LLM-enhanced reports:
  python llm_report_formatter.py rubble_crew_analysis.json --name "Episode 101" --fallback

  The system is production-ready and provides exactly the professional analysis reporting format you
  requested, with CSV batch processing and LLM training capabilities!


## ðŸ“¦ **Repair Package Structure**

When auto-repair creates a package, you get a comprehensive bundle:

```
Episode_101_sync_repair_20250912_143022/
â”œâ”€â”€ original_dub.mov              # Original file
â”œâ”€â”€ repaired_dub.mov              # Corrected file  
â”œâ”€â”€ analysis_report.json          # Technical analysis data
â”œâ”€â”€ repair_report.md              # Human-readable report
â”œâ”€â”€ repair_locations.json         # Specific correction points
â”œâ”€â”€ sync_visualization.png        # Timeline visualization
â””â”€â”€ package_summary.txt           # Overview document

# Plus optional ZIP archive:
Episode_101_sync_repair_20250912_143022.zip
```

### **Package Contents:**

- **ðŸ“¹ Original + Repaired Files**: Compare before and after
- **ðŸ“Š Analysis Data**: Complete JSON with all measurements  
- **ðŸ“‹ Professional Reports**: LLM-generated explanations
- **ðŸŽ¯ Correction Details**: Exactly where repairs were applied
- **ðŸ“ˆ Visualizations**: Charts showing sync issues and corrections
- **ðŸ“„ Summary**: Quick overview of all contents

## ðŸŽµ **Smart Playback Preview**

The web UI now includes intelligent playback preview:

1. **Load Files**: Upload master and dub files
2. **Run Analysis**: System automatically uses long method
3. **Preview Corrections**: 
   - **Original Mode**: Hear files as-is
   - **Corrected Mode**: Hear how repair would sound
   - **Preview Mode**: Visual indicators + corrections
4. **Interactive Timeline**: Click segments to jump to problem areas
5. **A/B Comparison**: Toggle between original and corrected
6. **Apply Repair**: Generate actual corrected file

### **Preview Features:**
- **ðŸŽšï¸ Volume Controls**: Individual master/dub levels
- **ðŸ“» Pan Controls**: Separate to left/right channels  
- **ðŸ“Š Segment Visualization**: Color-coded quality indicators
- **â° Real-time Updates**: Live correction application
- **ðŸŽ¯ Problem Region Jumping**: Click timeline to navigate

This system provides everything you need for comprehensive sync analysis from single files to large-scale batch operations with professional reporting, intelligent auto-repair, and real-time preview capabilities!




All set â€” Iâ€™ve added oneâ€‘shot CSV support (analyze + autoâ€‘repair + package) to the batch CLI.

What I Changed

csv_batch_processor.py:1: Added flags and logic to perform optional autoâ€‘repair and packaging per row.
New flags: --auto-repair, --repair-threshold, --repair-output-dir, --create-package, --package-dir.
Summary CSV now includes Repaired_Output, Package_Dir, Package_Zip when enabled.
Oneâ€‘Shot CSV Command

Analyze + autoâ€‘repair + package in one go:
python csv_batch_processor.py example_batch.csv --output-dir batch_results --auto-repair --repair-threshold 100 --repair-output-dir ./repaired_sync_files --create-package --package-dir ./repair_packages --plot --max-workers 3
Outputs

Analysis JSON, plots, reports: batch_results/
Repaired files: repaired_sync_files/
Packages (folder + ZIP): repair_packages/
Batch summaries:
batch_results/batch_processing_summary.json
batch_results/batch_results_summary.csv (now includes repaired/package columns)
Notes

Autoâ€‘repair triggers when offset >= repair_threshold based on each rowâ€™s analysis JSON.
Packaging includes analysis JSON, repaired file, markdown report, visualization, and summary.
Ensure ffmpeg/ffprobe are on PATH.

intelligent_sync_repair.py: Changed the intermediate video extract to MOV so we can copy any ProRes/H.264 stream without reâ€‘encode.
File: intelligent_sync_repair.py
Change: temp video path video.mp4 â†’ video.mov, keeps -c:v copy
Also prints ffmpeg stderr on failure for easier debugging
What to do now

Reâ€‘run your CSV batch with autoâ€‘repair and packaging. Example:
python csv_batch_processor.py Rubble.csv --output-dir batch_results --auto-repair --repair-threshold 100 --repair-output-dir ./repaired_sync_files --create-package --package-dir ./repair_packages --plot --max-workers 3
Outputs remain .mov because we preserve the original extension (safe for ProRes).
